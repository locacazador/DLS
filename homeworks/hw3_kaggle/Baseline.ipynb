{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK7oX5qdEEYr"
   },
   "source": [
    "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500 height=450/></p>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Домашнее задание. Продвинутый поток. Осень 2020</b></h3>\n",
    "\n",
    "Это домашнее задание будет посвящено полноценному решению задачи машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlB-owfaEEYs"
   },
   "source": [
    "Есть две части этого домашнего задания: \n",
    "* Сделать полноценный отчет о вашей работе: как вы обработали данные, какие модели попробовали и какие результаты получились (максимум 10 баллов). За каждую выполненную часть будет начислено определенное количество баллов.\n",
    "* Лучшее решение отправить в соревнование на [kaggle](https://www.kaggle.com/t/f50bc21dbe0e42dabe5e32a21f2e5235) (максимум 5 баллов). За прохождение определенного порогов будут начисляться баллы.\n",
    "\n",
    "\n",
    "**Обе части будут проверяться в формате peer-review. Т.е. вашу посылку на степик будут проверять несколько других студентов и аггрегация их оценок будет выставлена. В то же время вам тоже нужно будет проверить несколько других учеников.**\n",
    "\n",
    "**Пожалуйста, делайте свою работу чистой и понятной, чтобы облегчить проверку. Если у вас будут проблемы с решением или хочется совета, то пишите в наш чат в телеграме или в лс @runfme. Если вы захотите проаппелировать оценку, то пипшите в лс @runfme.**\n",
    "\n",
    "**Во всех пунктах указания это минимальный набор вещей, которые стоит сделать. Если вы можете сделать какой-то шаг лучше или добавить что-то свое - дерзайте!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu_JvqcBEN8Y"
   },
   "source": [
    "# Как проверять?\n",
    "\n",
    "Ставьте полный балл, если выполнены все рекомендации или сделано что-то более интересное и сложное. За каждый отсустствующий пункт из рекомендация снижайте 1 балл."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ninJ63mJEEYt"
   },
   "source": [
    "# Метрика. \n",
    "\n",
    "Перед решением любой задачи важно понимать, как будет оцениваться ваше решение. В данном случае мы используем стандартную для задачи классификации метрику ROC-AUC. Ее можно вычислить используя только предсказанные вероятности и истинные классы без конкретного порога классификации + она раотает даже если классы в данных сильно несбалансированны (примеров одного класса в десятки раз больше примеров длугого). Именно поэтому она очень удобна для соревнований.\n",
    "\n",
    "Посчитать ее легко:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:35:48.823770Z",
     "start_time": "2020-10-28T06:35:45.976920Z"
    },
    "id": "SQIrka7yEEYu",
    "outputId": "ef45a9f2-7571-47b1-e697-b474b65cb0fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = [\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1\n",
    "]\n",
    "\n",
    "y_predictions = [\n",
    "    0.1,\n",
    "    0.9,\n",
    "    0.4,\n",
    "    0.6,\n",
    "    0.61\n",
    "]\n",
    "\n",
    "roc_auc_score(y_true, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrDNNkNTEEYz"
   },
   "source": [
    "# Первая часть. Исследование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:35:51.176769Z",
     "start_time": "2020-10-28T06:35:49.622883Z"
    },
    "id": "lzLqEeZKEEYz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOlxdURSEEY3"
   },
   "source": [
    "## Загрузка данных (2 балла)\n",
    "\n",
    "1) Посмотрите на случайные строчки. \n",
    "\n",
    "2) Посмотрите, есть ли в датасете незаполненные значения (nan'ы) с помощью data.isna() или data.info() и, если нужно, замените их на что-то. Будет хорошо, если вы построите табличку с количеством nan в каждой колонке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:35:57.552108Z",
     "start_time": "2020-10-28T06:35:57.518798Z"
    },
    "id": "pw-Brue9EEY3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:36:20.009493Z",
     "start_time": "2020-10-28T06:36:20.000546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClientPeriod                0\n",
       "MonthlySpending             0\n",
       "TotalSpent                  0\n",
       "Sex                         0\n",
       "IsSeniorCitizen             0\n",
       "HasPartner                  0\n",
       "HasChild                    0\n",
       "HasPhoneService             0\n",
       "HasMultiplePhoneNumbers     0\n",
       "HasInternetService          0\n",
       "HasOnlineSecurityService    0\n",
       "HasOnlineBackup             0\n",
       "HasDeviceProtection         0\n",
       "HasTechSupportAccess        0\n",
       "HasOnlineTV                 0\n",
       "HasMovieSubscription        0\n",
       "HasContractPhone            0\n",
       "IsBillingPaperless          0\n",
       "PaymentMethod               0\n",
       "Churn                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:36:28.350483Z",
     "start_time": "2020-10-28T06:36:28.334526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5282 entries, 0 to 5281\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   ClientPeriod              5282 non-null   int64  \n",
      " 1   MonthlySpending           5282 non-null   float64\n",
      " 2   TotalSpent                5282 non-null   object \n",
      " 3   Sex                       5282 non-null   object \n",
      " 4   IsSeniorCitizen           5282 non-null   int64  \n",
      " 5   HasPartner                5282 non-null   object \n",
      " 6   HasChild                  5282 non-null   object \n",
      " 7   HasPhoneService           5282 non-null   object \n",
      " 8   HasMultiplePhoneNumbers   5282 non-null   object \n",
      " 9   HasInternetService        5282 non-null   object \n",
      " 10  HasOnlineSecurityService  5282 non-null   object \n",
      " 11  HasOnlineBackup           5282 non-null   object \n",
      " 12  HasDeviceProtection       5282 non-null   object \n",
      " 13  HasTechSupportAccess      5282 non-null   object \n",
      " 14  HasOnlineTV               5282 non-null   object \n",
      " 15  HasMovieSubscription      5282 non-null   object \n",
      " 16  HasContractPhone          5282 non-null   object \n",
      " 17  IsBillingPaperless        5282 non-null   object \n",
      " 18  PaymentMethod             5282 non-null   object \n",
      " 19  Churn                     5282 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(16)\n",
      "memory usage: 825.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из информации data.info() видно, что TotalSpent имеет Dtype == object, в то время как по существу данные должны представлять собой вещественные числа. Так как поиск isna не дал результатов, то следует предположить, что там находятся какие-то символьные артефакты. Чтобы пронаблюдать их - сделаем сортировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:37:08.861440Z",
     "start_time": "2020-10-28T06:37:08.854462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', ' ', ' ', ..., '997.65', '998.1', '999.9'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(data.TotalSpent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что присутствуют пробельные символы в значениях вместо вещественных чисел. Посмотрим, какое количество таких объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:50:40.425951Z",
     "start_time": "2020-10-28T06:50:40.417995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', '100.2', '100.25', ..., '997.65', '998.1', '999.9'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.TotalSpent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:53:40.846455Z",
     "start_time": "2020-10-28T06:53:40.840472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.where(data.TotalSpent == ' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропущенные данные средними значениями по всей выборке. Для этого совершим два последовательных действия:\n",
    "* Превратим все пробельные значения в np.nan, чтобы удобнее было работать в модуле np\n",
    "* Скастим все значения в float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:59:30.870445Z",
     "start_time": "2020-10-28T06:59:30.865458Z"
    }
   },
   "outputs": [],
   "source": [
    "data['TotalSpent'] = data['TotalSpent'].replace(' ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T06:59:44.937314Z",
     "start_time": "2020-10-28T06:59:44.932328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(data.TotalSpent.isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим временный объект pandas для хранения колонки TotalSpent без NA\n",
    "data_tmp = data.TotalSpent.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:00:29.484928Z",
     "start_time": "2020-10-28T10:00:29.401075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Преобразуем в float64 из строк\n",
    "data_tmp = data_tmp.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T09:58:32.469678Z",
     "start_time": "2020-10-28T09:58:32.465714Z"
    }
   },
   "outputs": [],
   "source": [
    "# найдем индексы, где находятся пропуски в исходных данных\n",
    "indexes_of_na = np.where(data.TotalSpent.isna())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:03:34.619995Z",
     "start_time": "2020-10-28T10:03:34.609023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Заполним пустые данные средними значениями\n",
    "data.TotalSpent.iloc[indexes_of_na] = data_tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:04:40.366563Z",
     "start_time": "2020-10-28T10:04:40.281814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Преобразуем исходные объекты в числа\n",
    "data.TotalSpent =  data.TotalSpent.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:39:04.417204Z",
     "start_time": "2020-10-28T10:39:04.411244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем среднее для проверки. Оно должно было остаться таким же\n",
    "data.TotalSpent.mean() == data_tmp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T10:05:42.961243Z",
     "start_time": "2020-10-28T10:05:42.954263Z"
    },
    "id": "KgnkkF5bEEY9"
   },
   "outputs": [],
   "source": [
    "# Для вашего удобства списки с именами разных колонок\n",
    "\n",
    "# Числовые признаки\n",
    "num_cols = [\n",
    "    'ClientPeriod',\n",
    "    'MonthlySpending',\n",
    "    'TotalSpent'\n",
    "]\n",
    "\n",
    "# Категориальные признаки\n",
    "cat_cols = [\n",
    "    'Sex',\n",
    "    'IsSeniorCitizen',\n",
    "    'HasPartner',\n",
    "    'HasChild',\n",
    "    'HasPhoneService',\n",
    "    'HasMultiplePhoneNumbers',\n",
    "    'HasInternetService',\n",
    "    'HasOnlineSecurityService',\n",
    "    'HasOnlineBackup',\n",
    "    'HasDeviceProtection',\n",
    "    'HasTechSupportAccess',\n",
    "    'HasOnlineTV',\n",
    "    'HasMovieSubscription',\n",
    "    'HasContractPhone',\n",
    "    'IsBillingPaperless',\n",
    "    'PaymentMethod'\n",
    "]\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "target_col = 'Churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK370bPCEEZD"
   },
   "source": [
    "## Анализ данных (3 балла)\n",
    "\n",
    "1) Для численных призанков постройте гистограмму (*plt.hist(...)*) или boxplot (*plt.boxplot(...)*). Для категориальных посчитайте количество каждого значения для каждого признака. Для каждой колонки надо сделать *data.value_counts()* и построить bar диаграммы *plt.bar(...)* или круговые диаграммы *plt.pie(...)* (хорошо, елси вы сможете это сделать на одном гарфике с помощью *plt.subplots(...)*). \n",
    "\n",
    "2) Посмотрите на распределение целевой переменной и скажите, являются ли классы несбалансированными.\n",
    "\n",
    "3) (Если будет желание) Поиграйте с разными библиотеками для визуализации - *sns*, *pandas_visual_analysis*, etc.\n",
    "\n",
    "Второй пункт очень важен, потому что существуют задачи классификации с несбалансированными классами. Например, это может значить, что в датасете намного больше примеров 0 класса. В таких случаях нужно 1) не использовать accuracy как метрику 2) использовать методы борьбы с imbalanced dataset (обычно если датасет сильно несбалансирован, т.е. класса 1 в 20 раз меньше класса 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZkbgFJZEEZE"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg60u3QDEEZH"
   },
   "source": [
    "(Дополнительно) Если вы нашли какие-то ошибки в данных или выбросы, то можете их убрать. Тут можно поэксперементировать с обработкой данных как угодно, но не за баллы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwfksF1gEEZI"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DviiJd8REEZK"
   },
   "source": [
    "## Применение линейных моделей (3 балла)\n",
    "\n",
    "1) Обработайте данные для того, чтобы к ним можно было применить LogisticRegression. Т.е. отнормируйте числовые признаки, а категориальные закодируйте с помощью one-hot-encoding'а. \n",
    "\n",
    "2) С помощью кроссвалидации или разделения на train/valid выборку протестируйте разные значения гиперпараметра C и выберите лучший (можно тестировать С=100, 10, 1, 0.1, 0.01, 0.001) по метрике ROC-AUC. \n",
    "\n",
    "Если вы разделяете на train/valid, то используйте LogisticRegressionCV. Он сам при вызове .fit() подберет параметр С. (не забудьте передать scroing='roc_auc', чтобы при кроссвалидации сравнивались значения этой метрики, и refit=True, чтобы при потом модель обучилась на всем датасете с лучшим параметром C). \n",
    "\n",
    "\n",
    "(более сложный вариант) Если вы будете использовать кроссвалидацию, то преобразования данных и LogisticRegression нужно соединить в один Pipeline с помощью make_pipeline, как это делалось во втором семинаре. Потом pipeline надо передать в GridSearchCV. Для one-hot-encoding'a можно испльзовать комбинацию LabelEncoder + OneHotEncoder (сначала превращаем строчки в числа, а потом числа првращаем в one-hot вектора.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHCLDmwqEEZL"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2Yv3uYtEEZO"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVahy6JKEEZQ"
   },
   "source": [
    "Выпишите какое лучшее качество и с какими параметрами вам удалось получить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36729TOQEEZR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlTeVy7fEEZR"
   },
   "source": [
    "## Применение градиентного бустинга (2 балла)\n",
    "\n",
    "Если вы хотите получить баллы за точный ответ, то стоит попробовать градиентный бустинг. Часто градиентный бустинг с дефолтными параметрами даст вам 80% результата за 0% усилий.\n",
    "\n",
    "Мы будем использовать catboost, поэтому нам не надо кодировать категориальные признаки. catboost сделает это сам (в .fit() надо передать cat_features=cat_cols). А численные признаки нормировать для моделей, основанных на деревьях не нужно.\n",
    "\n",
    "1) Разделите выборку на train/valid. Протестируйте catboost cо стандартными параметрами.\n",
    "\n",
    "2) Протестируйте разные занчения параметроа количества деревьев и learning_rate'а и выберите лучшую по метрике ROC-AUC комбинацию. \n",
    "\n",
    "(Дополнительно) Есть некоторые сложности с тем, чтобы использовать CatBoostClassifier вместе с GridSearchCV, поэтому мы не просим использовать кроссвалидацию. Но можете попробовать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fioxxlp-EEZS"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf4Kjt96EEZU"
   },
   "source": [
    "Выпишите какое лучшее качество и с какими параметрами вам удалось получить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2d9GolXEEZV"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDMXbvNZEEZV"
   },
   "source": [
    "# Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_P4wFNaEEZW",
    "outputId": "1fba5dfc-88e4-49e3-ed8a-afe21ae3325a"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-7d881febecc7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-7d881febecc7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    best_model = # какая-то предыдущая модель\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "best_model = # какая-то предыдущая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfSufx0CEEZZ"
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('./test.csv')\n",
    "submission = pd.read_csv('./submission.csv')\n",
    "\n",
    "submission['Churn'] = # best_model.predict_proba(X_test) / best_model.predict(X_test)\n",
    "submission.to_csv('./my_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkxjbGkVEEZc"
   },
   "source": [
    "# Kaggle (5 баллов)\n",
    "\n",
    "Как выставить баллы:\n",
    "\n",
    "1) 1 >= roc auc > 0.84 это 5 баллов\n",
    "\n",
    "2) 0.84 >= roc auc > 0.7 это 3 балла\n",
    "\n",
    "3) 0.7 >= roc auc > 0.6 это 1 балл\n",
    "\n",
    "4) 0.6 >= roc auc это 0 баллов\n",
    "\n",
    "\n",
    "Для выполнения задания необходимо выполнить следующие шаги.\n",
    "* Зарегистрироваться на платформе [kaggle.com](kaggle.com). Процесс выставления оценок будет проходить при подведении итогового рейтинга. Пожалуйста, укажите во вкладке Team -> Team name свои имя и фамилию в формате Имя_Фамилия (важно, чтобы имя и фамилия совпадали с данными на Stepik).\n",
    "* Обучить модель, получить файл с ответами в формате .csv и сдать его в конкурс. Пробуйте и экспериментируйте. Обратите внимание, что вы можете выполнять до 20 попыток сдачи на kaggle в день.\n",
    "* После окончания соревнования отправить в итоговый ноутбук с решением на степик. \n",
    "* После дедлайна проверьте посылки других участников по критериям. Для этого надо зайти на степик, скачать их ноутбук и проверить скор в соревновании."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
